<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Python [1, -1][x == 0] 写法解释和用处</title>
    <url>/Python-1-1-x-0-%E5%86%99%E6%B3%95%E8%A7%A3%E9%87%8A%E5%92%8C%E7%94%A8%E5%A4%84/</url>
    <content><![CDATA[<h3 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h3><p>这种写法通俗形式为 <strong>[条件为假, 条件为真][判断条件]</strong><br>在 Python 中，布尔型 True 转变为整数等于 1，False 转变为整数等于 0<br>所以条件为真时，返回第二个数，条件为假时，返回第一个数</p>
<h3 id="用处"><a href="#用处" class="headerlink" title="用处"></a>用处</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> x == <span class="number">0</span>:</span><br><span class="line">    a = -<span class="number">1</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    a = <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>可以写成这样的形式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">1</span>, -<span class="number">1</span>][x == <span class="number">0</span>]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Dijkstra 最短路径算法 Python 实现</title>
    <url>/Dijkstra-%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95-Python-%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>使用 Dijkstra 算法求图中的任意顶点到其它顶点的最短路径（求出需要经过那些点以及最短距离）。</p>
<p>以下图为例：</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_1.png" alt="image"></p>
<span id="more"></span>

<h3 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h3><p>可以使用二维数组来存储顶点之间边的关系</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_2.png" alt="image"></p>
<p>首先需要用一个一维数组 dis 来存储 初始顶点到其余各个顶点的初始路程，以求 1 顶点到其它各个顶点为例：</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_3.png" alt="image"></p>
<p>将此时 dis 数组中的值称为最短路的“估计值”。</p>
<p>既然是求 1 号顶点到其余各个顶点的最短路程，那就先找一个离 1 号顶点最近的顶点。通过数组 dis 可知当前离 1 号顶点最近是 2 号顶点。当选择了 2 号顶点后，dis[2] 的值就已经从“估计值”变为了“确定值”，即 1 号顶点到 2 号顶点的最短路程就是当前 dis[2]值。为什么呢？因为目前离 1 号顶点最近的是 2 号顶点，并且这个图所有的边都是正数，那么肯定不可能通过第三个顶点中转，使得 1 号顶点到 2 号顶点的路程进一步缩短了。</p>
<p>既然选了 2 号顶点，接下来再来看 2 号顶点有哪些出边。有 2-&gt;3 和 2-&gt;4 这两条边。先讨论通过 2-&gt;3 这条边能否让 1 号顶点到 3 号顶点的路程变短。也就是说现在比较 dis[3] 和 dis[2] + G[2][3]的大小。其中 dis[3] 表示 1 号顶点到 3 号顶点的路程。dis[2] + G[2][3] 中 dis[2] 表示 1 号顶点到 2 号顶点的路程，G[2][3] 表示 2-&gt;3 这条边。所以 dis[2] + G[2][3] 就表示从 1 号顶点先到 2 号顶点，再通过 2-&gt;3 这条边，到达 3 号顶点的路程。</p>
<p>在本例中 dis[3] = 12，dis[2] + G[2][3] = 1 + 9 = 10，dis[3] &gt; dis[2] + G[2][3]，所以 dis[3] 要更新为 10。这个过程有个专业术语叫做“松弛”。即 1 号顶点到 3 号顶点的路程即 dis[3]，通过 2-&gt;3 这条边松弛成功。这是 Dijkstra 算法的主要思想：通过“边”来松弛初始顶点到其余各个顶点的路程。</p>
<p>同理通过 2-&gt;4（G[2][4]），可以将 dis[4]的值从 ∞ 松弛为 4（dis[4] 初始为 ∞，dis[2] + G[2][4] = 1 + 3 = 4，dis[4] &gt; dis[2] + G[2][4]，所以 dis[4] 要更新为 4）。</p>
<p>刚才对 2 号顶点所有的出边进行了松弛。松弛完毕之后 dis 数组为：</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_4.png" alt="image"></p>
<p>接下来，继续在剩下的 3、4、5 和 6 号顶点中，选出离 1 号顶点最近的顶点。通过上面更新过 dis 数组，当前离 1 号顶点最近是 4 号顶点。此时，dis[4] 的值已经从“估计值”变为了“确定值”。下面继续对 4 号顶点的所有出边（4-&gt;3，4-&gt;5 和 4-&gt;6）用刚才的方法进行松弛。松弛完毕之后 dis 数组为：</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_5.png" alt="image"></p>
<p>继续在剩下的 3、5 和 6 号顶点中，选出离 1 号顶点最近的顶点，这次选择 3 号顶点。此时，dis[3] 的值已经从“估计值”变为了“确定值”。对 3 号顶点的所有出边（3-&gt;5）进行松弛。松弛完毕之后 dis 数组为：</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_6.png" alt="image"></p>
<p>继续在剩下的 5 和 6 号顶点中，选出离 1 号顶点最近的顶点，这次选择 5 号顶点。此时，dis[5] 的值已经从“估计值”变为了“确定值”。对5号顶点的所有出边（5-&gt;4）进行松弛。松弛完毕之后 dis 数组为：</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_7.png" alt="image"></p>
<p>最后对 6 号顶点所有点出边进行松弛。因为这个例子中 6 号顶点没有出边，因此不用处理。到此，dis 数组中所有的值都已经从“估计值”变为了“确定值”。</p>
<p>最终 dis 数组如下，这便是 1 号顶点到其余各个顶点的最短路径。</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_8.png" alt="image"></p>
<p>总结一下刚才的算法。算法的基本思想是：每次找到离源点（上面例子的源点就是 1 号顶点）最近的一个顶点，然后以该顶点为中心进行扩展，最终得到源点到其余所有点的最短路径。基本步骤如下：</p>
<ol>
<li>将所有的顶点分为两部分：已知最短路程的顶点集合 P 和未知最短路径的顶点集合 Q。最开始，已知最短路径的顶点集合 P 中只有源点一个顶点。这里用一个 visited[ i ]数组来记录哪些点在集合 P 中。例如对于某个顶点 i，如果 visited[ i ]为 1 则表示这个顶点在集合 P 中，如果 visited[ i ]为 0 则表示这个顶点在集合 Q 中；</li>
<li>设置源点 s 到自己的最短路径为 0 即 dis = 0。若存在源点有能直接到达的顶点 i，则把 dis[ i ]设为 G[s][ i ]。同时把所有其它（源点不能直接到达的）顶点的最短路径为设为 ∞；</li>
<li>在集合 Q 的所有顶点中选择一个离源点 s 最近的顶点  u（即 dis[u] 最小）加入到集合 P。并考察所有以点 u 为起点的边，对每一条边进行松弛操作。例如存在一条从 u 到 v 的边，那么可以通过将边 u-&gt;v 添加到尾部来拓展一条从 s 到 v 的路径，这条路径的长度是 dis[u] + G[u][v]。如果这个值比目前已知的 dis[v] 的值要小，我们可以用新值来替代当前 dis[v] 中的值；</li>
<li>重复第 3 步，如果集合 Q 为空，算法结束。最终 dis 数组中的值就是源点到所有顶点的最短路径</li>
</ol>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ol>
<li><p>Dijkstra 算法不能应用于有负权重的图</p>
</li>
<li><p>Dijkstra 时间复杂度为 O(N<sup>2</sup>)</p>
</li>
</ol>
<h3 id="Python-实现"><a href="#Python-实现" class="headerlink" title="Python 实现"></a>Python 实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Dijkstra</span>(<span class="params">G, start</span>):</span></span><br><span class="line">    <span class="comment"># 输入是从 0 开始，所以起始点减 1</span></span><br><span class="line">    start = start - <span class="number">1</span></span><br><span class="line">    inf = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    node_num = <span class="built_in">len</span>(G)</span><br><span class="line">    <span class="comment"># visited 代表哪些顶点加入过</span></span><br><span class="line">    visited = [<span class="number">0</span>] * node_num</span><br><span class="line">    <span class="comment"># 初始顶点到其余顶点的距离</span></span><br><span class="line">    dis = &#123;node: G[start][node] <span class="keyword">for</span> node <span class="keyword">in</span> <span class="built_in">range</span>(node_num)&#125;</span><br><span class="line">    <span class="comment"># parents 代表最终求出最短路径后，每个顶点的上一个顶点是谁，初始化为 -1，代表无上一个顶点</span></span><br><span class="line">    parents = &#123;node: -<span class="number">1</span> <span class="keyword">for</span> node <span class="keyword">in</span> <span class="built_in">range</span>(node_num)&#125;</span><br><span class="line">    <span class="comment"># 起始点加入进 visited 数组</span></span><br><span class="line">    visited[start] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 最开始的上一个顶点为初始顶点</span></span><br><span class="line">    last_point = start</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(node_num - <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 求出 dis 中未加入 visited 数组的最短距离和顶点</span></span><br><span class="line">        min_dis = inf</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(node_num):</span><br><span class="line">            <span class="keyword">if</span> visited[j] == <span class="number">0</span> <span class="keyword">and</span> dis[j] &lt; min_dis:</span><br><span class="line">                min_dis = dis[j]</span><br><span class="line">                <span class="comment"># 把该顶点做为下次遍历的上一个顶点</span></span><br><span class="line">                last_point = j</span><br><span class="line">        <span class="comment"># 最短顶点假加入 visited 数组</span></span><br><span class="line">        visited[last_point] = <span class="number">1</span></span><br><span class="line">        <span class="comment"># 对首次循环做特殊处理，不然在首次循环时会没法求出该点的上一个顶点</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            parents[last_point] = start + <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(node_num):</span><br><span class="line">            <span class="keyword">if</span> G[last_point][k] &lt; inf <span class="keyword">and</span> dis[k] &gt; dis[last_point] + G[last_point][k]:</span><br><span class="line">                <span class="comment"># 如果有更短的路径，更新 dis 和 记录 parents</span></span><br><span class="line">                dis[k] = dis[last_point] + G[last_point][k]</span><br><span class="line">                parents[k] = last_point + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 因为从 0 开始，最后把顶点都加 1</span></span><br><span class="line">    <span class="keyword">return</span> &#123;key + <span class="number">1</span>: values <span class="keyword">for</span> key, values <span class="keyword">in</span> dis.items()&#125;, &#123;key + <span class="number">1</span>: values <span class="keyword">for</span> key, values <span class="keyword">in</span> parents.items()&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    inf = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    G = [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">12</span>, inf, inf, inf],</span><br><span class="line">         [inf, <span class="number">0</span>, <span class="number">9</span>, <span class="number">3</span>, inf, inf],</span><br><span class="line">         [inf, inf, <span class="number">0</span>, inf, <span class="number">5</span>, inf],</span><br><span class="line">         [inf, inf, <span class="number">4</span>, <span class="number">0</span>, <span class="number">13</span>, <span class="number">15</span>],</span><br><span class="line">         [inf, inf, inf, inf, <span class="number">0</span>, <span class="number">4</span>],</span><br><span class="line">         [inf, inf, inf, inf, inf, <span class="number">0</span>]]</span><br><span class="line">    dis, parents = Dijkstra(G, <span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;dis: &quot;</span>, dis)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;parents: &quot;</span>, parents)</span><br></pre></td></tr></table></figure>

<p>输出为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dis:  &#123;<span class="number">1</span>: <span class="number">0</span>, <span class="number">2</span>: <span class="number">1</span>, <span class="number">3</span>: <span class="number">8</span>, <span class="number">4</span>: <span class="number">4</span>, <span class="number">5</span>: <span class="number">13</span>, <span class="number">6</span>: <span class="number">17</span>&#125;</span><br><span class="line">parents:  &#123;<span class="number">1</span>: -<span class="number">1</span>, <span class="number">2</span>: <span class="number">1</span>, <span class="number">3</span>: <span class="number">4</span>, <span class="number">4</span>: <span class="number">2</span>, <span class="number">5</span>: <span class="number">3</span>, <span class="number">6</span>: <span class="number">5</span>&#125;</span><br></pre></td></tr></table></figure>

<p>如果求 1 号顶点到 6 号顶点的最短距离，dis[6] = 17，所以最短距离为 17。</p>
<p>再看 parents[6] = 5，说明 6 号顶点的上一个顶点为 5，parents[5] = 3，说明 5 号顶点的上一个顶点为 3，以此类推，最终 1 号顶点到 6 号顶点的路径为 1-&gt;2-&gt;4-&gt;3-&gt;5-&gt;6。</p>
<h3 id="优化思路"><a href="#优化思路" class="headerlink" title="优化思路"></a>优化思路</h3><ul>
<li>其中每次找到离 1 号顶点最近的顶点的时间复杂度是 O(N)，可以用“堆”来优化，使得这一部分的时间复杂度降低到 O(logN)；</li>
<li>另外对于边数 M 少于 N<sup>2</sup> 的稀疏图来说（把 M 远小于 N<sup>2</sup> 的图称为稀疏图，而 M 相对较大的图称为稠密图），可以用邻接表来代替邻接矩阵，使得整个时间复杂度优化到 O((M+N)logN)。注意，在最坏的情况下 M 就是 N<sup>2</sup>，这样的话 MlogN 要比 N<sup>2</sup> 还要大。但是大多数情况下并不会有那么多边，所以 (M+N)logN 要比 N<sup>2</sup> 小很多</li>
</ul>
]]></content>
      <categories>
        <category>DS&amp;A</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DS&amp;A</tag>
        <tag>Dijkstra</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 日期格式，时间戳之间转换</title>
    <url>/Python-%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%EF%BC%8C%E6%97%B6%E9%97%B4%E6%88%B3%E4%B9%8B%E9%97%B4%E8%BD%AC%E6%8D%A2/</url>
    <content><![CDATA[<h3 id="获取当前时间戳"><a href="#获取当前时间戳" class="headerlink" title="获取当前时间戳"></a>获取当前时间戳</h3><ul>
<li>方法：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">now &#x3D; time.time()</span><br><span class="line">print(&#39;now:&#39;, now, &#39;\n&#39;, type(now))</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">now: 1498926743.1411922 </span><br><span class="line"> &lt;class &#39;float&#39;&gt;</span><br></pre></td></tr></table></figure>

<h3 id="获取当前日期"><a href="#获取当前日期" class="headerlink" title="获取当前日期"></a>获取当前日期</h3><span id="more"></span>

<ul>
<li>方法：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">datenow &#x3D; datetime.datetime.now()</span><br><span class="line">print(&#39;datenow:&#39;, datenow, &#39;\n&#39;, type(datenow))</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">datenow: 2017-07-02 00:34:35.272749 </span><br><span class="line"> &lt;class &#39;datetime.datetime&#39;&gt;</span><br></pre></td></tr></table></figure>

<h3 id="字符串格式更改"><a href="#字符串格式更改" class="headerlink" title="字符串格式更改"></a>字符串格式更改</h3><p>如a = “2017-07-02 00:34:35”，想改为 a = “2017/07/02 00:34:35”</p>
<ul>
<li>方法：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a &#x3D; &quot;2013-10-10 23:40:00&quot;</span><br><span class="line">timeArray &#x3D; time.strptime(a, &quot;%Y-%m-%d %H:%M:%S&quot;)                # 先转换为时间数组</span><br><span class="line">otherStyleTime &#x3D; time.strftime(&quot;%Y&#x2F;%m&#x2F;%d %H:%M:%S&quot;, timeArray)   # 转换为其他格式</span><br><span class="line">print(&#39;otherStyleTime:&#39;, otherStyleTime)</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">otherStyleTime: 2017&#x2F;07&#x2F;02 00:34:35</span><br></pre></td></tr></table></figure>

<h3 id="将字符串的时间转换为时间戳"><a href="#将字符串的时间转换为时间戳" class="headerlink" title="将字符串的时间转换为时间戳"></a>将字符串的时间转换为时间戳</h3><ul>
<li>方法：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a &#x3D; &quot;2017-07-02 00:34:35&quot; </span><br><span class="line">timeArray &#x3D; time.strptime(a, &quot;%Y-%m-%d %H:%M:%S&quot;)            # 将其转换为时间数组</span><br><span class="line">timeStamp &#x3D; int(time.mktime(timeArray))                      # 转换为时间戳</span><br><span class="line">print(&#39;timesStamp:&#39;, timeStamp)</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">timesStamp: 1498926875</span><br></pre></td></tr></table></figure>

<h3 id="时间戳转换为指定格式日期"><a href="#时间戳转换为指定格式日期" class="headerlink" title="时间戳转换为指定格式日期"></a>时间戳转换为指定格式日期</h3><ul>
<li>方法一：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">timeStamp &#x3D; 1498927046</span><br><span class="line">timeArray &#x3D; time.localtime(timeStamp)                              # 利用localtime()转换为时间数组</span><br><span class="line">otherStyleTime &#x3D; time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, timeArray)     # 格式化为需要的格式</span><br><span class="line">print(&#39;otherStyleTime:&#39;, otherStyleTime)</span><br></pre></td></tr></table></figure>

<ul>
<li>方法二：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">timeStamp &#x3D; 1498927046</span><br><span class="line">dateArray &#x3D; datetime.datetime.fromtimestamp(timeStamp)</span><br><span class="line">otherStyleTime &#x3D; dateArray.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;)</span><br><span class="line">print(&#39;otherStyleTime:&#39;, otherStyleTime)</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">otherStyleTime: 2017-07-02 00:37:26</span><br></pre></td></tr></table></figure>

<h3 id="获取当前时间并转换为指定日期格式"><a href="#获取当前时间并转换为指定日期格式" class="headerlink" title="获取当前时间并转换为指定日期格式"></a>获取当前时间并转换为指定日期格式</h3><ul>
<li>方法一：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">now &#x3D; int(time.time())                                             # 获得当前时间时间戳</span><br><span class="line">timeArray &#x3D; time.localtime(now)</span><br><span class="line">StyleTime &#x3D; time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, timeArray)</span><br><span class="line">print(&#39;StyleTime:&#39;, StyleTime)  </span><br></pre></td></tr></table></figure>

<ul>
<li>方法二：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">now &#x3D; datetime.datetime.now()                                 # 获得当前时间，这是时间数组格式</span><br><span class="line">StyleTime &#x3D; now.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;)                 # 转换为指定的格式</span><br><span class="line">print(&#39;StyleTime:&#39;, StyleTime)</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">StyleTime: 2017-07-02 00:16:30</span><br></pre></td></tr></table></figure>

<h3 id="获得三天前的时间"><a href="#获得三天前的时间" class="headerlink" title="获得三天前的时间"></a>获得三天前的时间</h3><ul>
<li>方法:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line">import datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">threeDayAgo &#x3D; (datetime.datetime.now() - datetime.timedelta(days &#x3D; 3))   # 先获得时间数组格式的日期</span><br><span class="line">timeStamp &#x3D; int(time.mktime(threeDayAgo.timetuple()))                    # 转换为时间戳</span><br><span class="line">threeDayAgo &#x3D; threeDayAgo.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;)                  # 转换为其他字符串格式</span><br><span class="line">print(&#39;threeDayAgo:&#39;, threeDayAgo)</span><br></pre></td></tr></table></figure>

<p>timedelta()的参数有:days, seconds, microseconds, milliseconds, minutes, hours, weeks</p>
<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">threeDayAgo: 2017-06-29 00:21:04</span><br></pre></td></tr></table></figure>

<h3 id="给定时间戳-计算该时间的几天前时间"><a href="#给定时间戳-计算该时间的几天前时间" class="headerlink" title="给定时间戳,计算该时间的几天前时间:"></a>给定时间戳,计算该时间的几天前时间:</h3><ul>
<li>方法:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">timeStamp &#x3D; 1498926852</span><br><span class="line">dateArray &#x3D; datetime.datetime.fromtimestamp(timeStamp)  # 先转换为datetime</span><br><span class="line">threeDayAgo &#x3D; dateArray - datetime.timedelta(days&#x3D;3)</span><br><span class="line">print(&#39;threeDayAgo:&#39;, threeDayAgo)</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">threeDayAgo: 2017-06-28 16:34:12</span><br></pre></td></tr></table></figure>

<p>参考上面，可以转换为其他的任意格式</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>极客时间 - 《Kafka核心技术与实战》 学习笔记 1</title>
    <url>/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-%E3%80%8AKafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/</url>
    <content><![CDATA[<h3 id="什么是-Kafka"><a href="#什么是-Kafka" class="headerlink" title="什么是 Kafka"></a>什么是 Kafka</h3><pre><code>Apache Kafka 是一款开源的消息引擎系统。
</code></pre>
<h3 id="Kafka-消息格式"><a href="#Kafka-消息格式" class="headerlink" title="Kafka 消息格式"></a>Kafka 消息格式</h3><pre><code>Kafka 使用的是纯二进制字节序列。
</code></pre>
<h3 id="Kafka-支持的消息引擎模型"><a href="#Kafka-支持的消息引擎模型" class="headerlink" title="Kafka 支持的消息引擎模型"></a>Kafka 支持的消息引擎模型</h3><pre><code>Kafka 同时支持两种消息引擎模型，点对点模型和发布 / 订阅模型。
</code></pre>
<h3 id="Topic-含义"><a href="#Topic-含义" class="headerlink" title="Topic 含义"></a>Topic 含义</h3><pre><code>在 Kafka 中，发布订阅的对象是主题（Topic），可以为每个业务、每个应用甚至是每类数据都创建专属的主题。
</code></pre>
<span id="more"></span>

<h3 id="Producer-和-Consumer-含义"><a href="#Producer-和-Consumer-含义" class="headerlink" title="Producer 和 Consumer 含义"></a>Producer 和 Consumer 含义</h3><pre><code>向主题发布消息的客户端应用程序称为生产者（Producer），生产者程序通常持续不断地向一个或多个主题发送消息，
而订阅这些主题消息的客户端应用程序就被称为消费者（Consumer）。
和生产者类似，消费者也能够同时订阅多个主题的消息。生产者和消费者统称为客户端（Clients）。
</code></pre>
<h3 id="Broker-含义"><a href="#Broker-含义" class="headerlink" title="Broker 含义"></a>Broker 含义</h3><pre><code>Kafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成，
Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。

虽然多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将不同的 Broker 分散运行在不同的机器上，
这样如果集群中某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也依然能够对外提供服务。
这其实就是 Kafka 提供高可用的手段之一。
</code></pre>
<h3 id="Replication-含义"><a href="#Replication-含义" class="headerlink" title="Replication 含义"></a>Replication 含义</h3><pre><code>实现高可用的另一个手段就是备份机制（Replication）。
备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝在 Kafka 中被称为副本（Replica）。

Kafka 定义了两类副本：领导者副本（Leader Replica）和追随者副本（Follower Replica）。
前者对外提供服务，这里的对外指的是与客户端程序进行交互；而后者只是被动地追随领导者副本而已，不能与外界进行交互。

副本的工作机制也很简单：生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。
至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。
</code></pre>
<h3 id="Partitioning-含义"><a href="#Partitioning-含义" class="headerlink" title="Partitioning 含义"></a>Partitioning 含义</h3><pre><code>Kafka 中的分区机制指的是将每个主题划分成多个分区（Partition），每个分区是一组有序的消息日志。
生产者生产的每条消息只会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，
这条消息要么在分区 0 中，要么在分区 1 中。
Kafka 的分区编号是从 0 开始的，如果 Topic 有 100 个分区，那么它们的分区号就是从 0 到 99。
</code></pre>
<h3 id="副本如何与分区联系在一起"><a href="#副本如何与分区联系在一起" class="headerlink" title="副本如何与分区联系在一起"></a>副本如何与分区联系在一起</h3><pre><code>副本是在分区这个层级定义的。
每个分区下可以配置若干个副本，其中只能有 1 个领导者副本和 N-1 个追随者副本。
生产者向分区写入消息，每条消息在分区中的位置信息由一个叫位移（Offset）的数据来表征。
分区位移总是从 0 开始，假设一个生产者向一个空分区写入了 10 条消息，那么这 10 条消息的位移依次是 0、1、2、......、9。
</code></pre>
<h3 id="Kafka-的三层消息架构"><a href="#Kafka-的三层消息架构" class="headerlink" title="Kafka 的三层消息架构"></a>Kafka 的三层消息架构</h3><pre><code>- 第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。
- 第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。
- 第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。
- 最后，客户端程序只能与分区的领导者副本进行交互。
</code></pre>
<h3 id="Broker-如何持久化数据"><a href="#Broker-如何持久化数据" class="headerlink" title="Broker 如何持久化数据"></a>Broker 如何持久化数据</h3><pre><code>Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。
因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。
Kafka 要定期地删除消息以回收磁盘。怎么删除呢？简单来说就是通过日志段（Log Segment）机制。
在 Kafka 底层，一个日志又进一步细分成多个日志段，消息被追加写到当前最新的日志段中，
当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。
Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。
</code></pre>
<h3 id="Kafka-中实现-P2P-模型的方法"><a href="#Kafka-中实现-P2P-模型的方法" class="headerlink" title="Kafka 中实现 P2P 模型的方法"></a>Kafka 中实现 P2P 模型的方法</h3><pre><code>在 Kafka 中实现这种 P2P 模型的方法就是引入了消费者组（Consumer Group）。
所谓的消费者组，指的是多个消费者实例共同组成一个组来消费一组主题。
这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它。
为什么要引入消费者组呢？主要是为了提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量（TPS）。
另外这里的消费者实例可以是运行消费者应用的进程，也可以是一个线程，它们都称为一个消费者实例（Consumer Instance）。
消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且更酷的是它们还能彼此协助。
假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个 Failed 实例之前负责的分区转移给其他活着的消费者。
这个过程就是 Kafka 中大名鼎鼎的“重平衡”（Rebalance）。
</code></pre>
<h3 id="消费者位移"><a href="#消费者位移" class="headerlink" title="消费者位移"></a>消费者位移</h3><pre><code>每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，
这个字段就是消费者位移（Consumer Offset）。
注意，这和上面所说的位移完全不是一个概念。
上面的“位移”表征的是分区内的消息位置，它是不变的，即一旦消息被成功写入到一个分区上，它的位移值就是固定的了。
而消费者位移则不同，它可能是随时变化的。
另外每个消费者有着自己的消费者位移，因此一定要区分这两类位移的区别。
</code></pre>
<h3 id="术语示意图"><a href="#术语示意图" class="headerlink" title="术语示意图"></a>术语示意图</h3><p align='center'>
    <img data-src='https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8AKafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_1.jpg'>
</p>
]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>uWSGI、WSGI 和 uwsgi</title>
    <url>/uWSGI%E3%80%81WSGI-%E5%92%8C-uwsgi/</url>
    <content><![CDATA[<h3 id="图解"><a href="#图解" class="headerlink" title="图解"></a>图解</h3><p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/uWSGI%E3%80%81WSGI%20%E5%92%8C%20uwsgi_1.jpg" alt="image"></p>
<span id="more"></span>

<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/uWSGI%E3%80%81WSGI%20%E5%92%8C%20uwsgi_2.jpg" alt="image"></p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/uWSGI%E3%80%81WSGI%20%E5%92%8C%20uwsgi_3.jpg" alt="image"></p>
<h4 id="WSGI"><a href="#WSGI" class="headerlink" title="WSGI"></a>WSGI</h4><p>wsgi server（比如 uWSGI）要和 wsgi application（比如 django ）交互，uWSGI 需要将过来的请求转给 django 处理，那么 uWSGI 和 django 的交互和调用就需要一个统一的规范，这个规范就是 WSGI。</p>
<p>WSGI，全称 Web Server Gateway Interface，或者 Python Web Server Gateway Interface，是为 Python 语言定义的 Web 服务器和 Web 应用程序或框架之间的一种简单而通用的接口。自从 WSGI 被开发出来以后，许多其它语言中也出现了类似接口。</p>
<p>WSGI 的官方定义是，the Python Web Server Gateway Interface。从名字就可以看出来，这东西是一个 Gateway，也就是网关。网关的作用就是在协议之间进行转换。</p>
<p>WSGI 是作为 Web 服务器与 Web 应用程序或应用框架之间的一种低级别的接口，以提升可移植 Web 应用开发的共同点。WSGI 是基于现存的 CGI 标准而设计的。</p>
<h4 id="uWSGI"><a href="#uWSGI" class="headerlink" title="uWSGI"></a>uWSGI</h4><p>uWSGI 是一个 Web 服务器，它实现了 WSGI 协议、uwsgi、http 等协议。Nginx 中 HttpUwsgiModule 的作用是与 uWSGI 服务器进行交换。</p>
<h4 id="uwsgi"><a href="#uwsgi" class="headerlink" title="uwsgi"></a>uwsgi</h4><p>与 WSGI 一样是一种通信协议，是 uWSGI 服务器的独占协议，用于定义传输信息的类型（type of information），每一个 uwsgi packet 前 4byte 为传输信息类型的描述，与 WSGI 协议是两种东西，据说该协议是 fcgi 协议的 10 倍快。</p>
<h4 id="FastCgi-协议，-uwsgi-协议与-http-协议有什么用？"><a href="#FastCgi-协议，-uwsgi-协议与-http-协议有什么用？" class="headerlink" title="FastCgi 协议， uwsgi 协议与 http 协议有什么用？"></a>FastCgi 协议， uwsgi 协议与 http 协议有什么用？</h4><p>nginx 和下游服务器交互就必须使用同一个协议，只要大家沟通好使用哪个协议，就可以正常运行了。</p>
<p>这三种协议就是 nginx 为了与下游服务器交互事先约定好的协议。</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>极客时间 - 《Redis核心技术与实战》 学习笔记 1</title>
    <url>/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/</url>
    <content><![CDATA[<h3 id="数据结构：快速的-Redis-有哪些慢操作？"><a href="#数据结构：快速的-Redis-有哪些慢操作？" class="headerlink" title="数据结构：快速的 Redis 有哪些慢操作？"></a>数据结构：快速的 Redis 有哪些慢操作？</h3><hr>
<ul>
<li>Redis 表现突出的原因</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
一方面，这是因为它是内存数据库，所有操作都在内存上完成，内存的访问速度本身就很快。<br>
另一方面，这要归功于它的数据结构。
这是因为，键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，
所以高效的数据结构是 Redis 快速处理数据的基础。
</pre>

<ul>
<li>底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。</li>
</ul>
<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_1.jpg" width="500" align=center>
</div><br>

<span id="more"></span>

<ul>
<li>键和值用什么结构组织？</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。<br>
一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。
所以，我们常说，一个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。<br>
哈希桶中的 entry 元素中保存了 \*key 和 \*value 指针，分别指向了实际的键和值，
这样一来，即使值是一个集合，也可以通过*value指针被查找到。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_2.jpg" width="500">
</div><br>

<ul>
<li>为什么哈希表操作变慢了？</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
哈希表的冲突问题和 rehash 可能带来的操作阻塞。<br>
Redis 解决哈希冲突的方式，就是链式哈希。<br>
但是，这里依然存在一个问题，哈希冲突链上的元素只能通过指针逐一查找再操作。<br>
如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，
这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。<br>
对于追求“快”的 Redis 来说，这是不太能接受的。<br>
所以，Redis 会对哈希表做 rehash 操作。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_3.jpg" width="500">
</div><br>

<ul>
<li>哈希表做 rehash</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。<br>
其实，为了使 rehash 操作更高效，Redis 默认使用了两个全局哈希表：
哈希表 1 和哈希表 2。
一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。
随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步：
  1. 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；
  2. 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；
  3. 释放哈希表 1 的空间。
<br>到此，我们就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用。<br>
这个过程看似简单，但是第二步涉及大量的数据拷贝，
如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，无法服务其他请求。
此时，Redis 就无法快速访问数据了。<br>
为了避免这个问题，Redis 采用了渐进式 rehash。
</pre>

<ul>
<li>渐进式 rehash</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求。<br>
每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中。<br>
等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。如下图所示：
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_4.jpg" width="500">
</div><br>

<ul>
<li>对于 String 类型来说，找到哈希桶就能直接增删改查了，所以，哈希表的 O(1) 操作复杂度也就是它的复杂度了。</li>
<li>压缩列表</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。<br>
和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；
压缩列表在表尾还有一个 zlend，表示列表结束。<br>
在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。<br>
而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_5.jpg" width="500">
</div><br>

<ul>
<li>跳表</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。<br>
具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位，如下图所示：
当数据量很大时，跳表的查找复杂度就是 O(logN)。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_6.jpg" width="500">
</div><br>

<ul>
<li>数据结构的时间复杂度</li>
</ul>
<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_7.jpg" width="500">
</div>

<ul>
<li><p>四句口诀</p>
<ul>
<li>单元素操作是基础；</li>
<li>范围操作非常耗时；</li>
<li>统计操作通常高效；</li>
<li>例外情况只有几个。</li>
</ul>
</li>
<li><p>单元素操作</p>
</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
是指每一种集合类型对单个数据实现的增删改查操作。<br>
例如，Hash 类型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。<br>
这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET 和 HDEL 是对哈希表做操作，所以它们的复杂度都是 O(1)；<br>
Set 类型用哈希表作为底层数据结构时，它的 SADD、SREM、SRANDMEMBER 复杂度也是 O(1)。<br>
这里，有个地方你需要注意一下，集合类型支持同时对多个元素进行增删改查，
例如 Hash 类型的 HMGET 和 HMSET，Set 类型的 SADD 也支持同时增加多个元素。<br>
此时，这些操作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，HMSET 增加 M 个元素时，复杂度就从 O(1) 变成 O(M) 了。
</pre>

<ul>
<li>范围操作</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
是指集合类型中的遍历操作，可以返回集合中的所有数据。<br>
比如 Hash 类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。<br>
这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免。<br>
Redis 从 2.8 版本开始提供了 SCAN 系列操作（包括 HSCAN，SSCAN 和 ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。<br>
这样一来，相比于 HGETALL、SMEMBERS 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻塞。
</pre>

<ul>
<li>统计操作</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
是指集合类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。<br>
这类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，
这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。
</pre>

<ul>
<li>例外情况</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。<br>
这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作来说，它们是在列表的头尾增删元素，
这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作。
</pre>

<ul>
<li>复杂度较高的 List 类型，它的两种底层实现结构：双向链表和压缩列表的操作复杂度都是 O(N)。因此，<strong>因地制宜地使用 List 类型</strong>。</li>
</ul>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>极客时间 - 《Redis核心技术与实战》 学习笔记 2</title>
    <url>/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2/</url>
    <content><![CDATA[<h3 id="高性能IO模型：为什么单线程Redis能那么快？"><a href="#高性能IO模型：为什么单线程Redis能那么快？" class="headerlink" title="高性能IO模型：为什么单线程Redis能那么快？"></a>高性能IO模型：为什么单线程Redis能那么快？</h3><hr>
<ul>
<li>Redis 单线程的理解</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写（数据读写）是由一个线程来完成的，
这也是 Redis 对外提供键值存储服务的主要流程。<br>
但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。
</pre>

<ul>
<li>Redis 为什么用单线程？</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
多线程编程模式面临共享资源的并发访问控制问题。<br>
并发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，
比如说，只是简单地采用一个粗粒度互斥锁，就会出现不理想的结果：
    即使增加了线程，大部分线程也在等待获取访问共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增加。<br>
而且，采用多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性。<br>
为了避免这些问题，Redis 直接采用了单线程模式。
</pre>

<ul>
<li>单线程 Redis 为什么那么快？</li>
</ul>
<span id="more"></span>

<pre style="font-size:0.9em; color:#666666;">
一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，
例如哈希表和跳表，这是它实现高性能的一个重要原因。<br>
另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。
</pre>

<ul>
<li>基本 IO 模型与阻塞点</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
以 Get 请求为例，为了处理一个 Get 请求，
需要监听客户端请求（bind/listen），
和客户端建立连接（accept），
从 socket 中读取请求（recv），
解析客户端发送请求（parse），
根据请求类型读取键值数据（get），
最后给客户端返回结果，即向 socket 中写回数据（send）。<br>
下图显示了这一过程，其中，bind/listen、accept、recv、parse 和 send 属于网络 IO 处理，而 get 属于键值数据操作。
既然 Redis 是单线程，那么，最基本的一种实现是在一个线程中依次执行上面说的这些操作。

但是，在这里的网络 IO 操作中，有潜在的阻塞点，分别是 accept() 和 recv()。<br>
当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里，
导致其他客户端无法和 Redis 建立连接。<br>
类似的，当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%202_1.jpg" width="500">
</div><br>

<ul>
<li>非阻塞模式</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
在 socket 模型中，不同操作调用后会返回不同的套接字类型。<br>
socket() 方法会返回主动套接字，然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。<br>
最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字。<br>
针对监听套接字，我们可以设置非阻塞模式：
    当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。
    但是，你要注意的是，调用 accept() 时，已经存在监听套接字了
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%202_2.jpg" width="500">
</div><br>

<ul>
<li>基于多路复用的高性能 I/O 模型</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。<br>
简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。<br>
内核会一直监听这些套接字上的连接请求或数据请求。<br>
一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。<br>
下图就是基于多路复用的 Redis IO 模型。
图中的多个 FD 就是刚才所说的多个套接字。<br>
Redis 网络框架调用 epoll 机制，让内核监听这些套接字。
此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，
也就是说，不会阻塞在某一个特定的客户端请求处理上。<br>
正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。<br>
为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，
即针对不同事件的发生，调用相应的处理函数。<br>
select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。

这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。<br>
这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。<br>
同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。<br>
因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%202_3.jpg" width="500">
</div>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>极客时间 - 《Redis核心技术与实战》 学习笔记 3</title>
    <url>/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3/</url>
    <content><![CDATA[<h3 id="AOF日志：宕机了，Redis如何避免数据丢失？"><a href="#AOF日志：宕机了，Redis如何避免数据丢失？" class="headerlink" title="AOF日志：宕机了，Redis如何避免数据丢失？"></a>AOF日志：宕机了，Redis如何避免数据丢失？</h3><hr>
<ul>
<li>Redis 的持久化主要有两大机制，即 AOF(Append Only File) 日志和 RDB(Redis DataBase) 快照。</li>
<li>AOF 日志是如何实现的？</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
AOF 日志写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%203_1.jpg" width="500">
</div><br>

<span id="more"></span>

<ul>
<li>AOF 为什么要先执行命令再记日志呢？</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，
而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。<br>
以 Redis 收到 “set testkey testvalue” 命令后记录的日志为例，看看 AOF 日志的内容。
其中，“*3” 表示当前命令有三个部分，每部分都是由 “$+数字” 开头，后面紧跟着具体的命令、键或值。
这里，“数字” 表示这部分中的命令、键或值一共有多少字节。
例如，“$3 set” 表示这部分有 3 个字节，也就是 “set” 命令。<br>
为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。
所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。<br>
而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，
否则，系统就会直接向客户端报错。<br>
所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。<br>
除此之外，AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%203_2.jpg" width="500">
</div><br>

<ul>
<li>AOF 两个潜在的风险</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。<br>
如果此时 Redis 是用作缓存，还可以从后端数据库重新读入数据进行恢复，
但是，如果 Redis 是直接用作数据库的话，此时，因为命令没有记入日志，所以就无法用日志进行恢复了。<br>
其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。<br>
这是因为，AOF 日志也是在<strong>主线程</strong>中执行的，
如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。
</pre>

<ul>
<li>三种写回策略</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
对于这个问题，AOF 机制给我们提供了三个选择，也就是 AOF 配置项 appendfsync 的三个可选。<br>
<ul>
  <li>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li>
  <li>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li>
  <li>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li>
</ul>
针对避免主线程阻塞和减少数据丢失问题，这三种写回策略都无法做到两全其美。
<ul>
  <li>“同步写回”可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能；</li>
  <li>“每秒写回”采用一秒写回一次的频率，避免了“同步写回”的性能开销，
虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。
所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中。</li>
  <li>虽然“操作系统控制的写回”在写完缓冲区后，就可以继续执行后续的命令，
但是落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了；</li>
</ul>
</pre>

<ul>
<li>三种策略的写回时机对比</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
想要获得高性能，就选择 No 策略；<br>
如果想要得到高可靠性保证，就选择 Always 策略；<br>
如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 Everysec 策略。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%203_3.jpg" width="500">
</div><br>

<ul>
<li> AOF 文件过大带来的性能问题</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
这里的“性能问题”，主要在于以下三个方面：<br>
  一是，文件系统本身对文件大小有限制，无法保存过大的文件；<br>
  二是，如果文件太大，之后再往里面追加命令记录的话，效率也会变低；<br>
  三是，如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，
        如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。
</pre>

<ul>
<li>AOF 重写机制</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
AOF 重写机制指的是，对过大的 AOF 文件进行重写，以此来压缩 AOF 文件的大小。<br>
具体的实现是：检查当前键值数据库中的键值对，记录键值对的最终状态，
从而实现对某个键值对重复操作后产生的多条操作记录压缩成一条的效果。进而实现压缩 AOF 文件的大小。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%203_4.jpg" width="500">
</div><br>

<ul>
<li>AOF 重写会阻塞吗?</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
和 AOF 日志由主线程写回不同，重写过程是由后台线程 bgrewriteaof 来完成的，
这也是为了避免阻塞主线程，导致数据库性能下降。<br>
</pre>

<ul>
<li>AOF 重写过程</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
重写的过程总结为“一个拷贝，两处日志”。<br>
一个拷贝：
    每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。<br>
    此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。<br>
    然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。<br>
两处日志：
    因为主线程未阻塞，仍然可以处理新来的操作。<br>
    此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。
    这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。<br>
    而第二处日志，
    就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。
    这样，重写日志也不会丢失最新的操作。
    等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。<br>
    此时，我们就可以用新的 AOF 文件替代旧文件了。
    
总结来说，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；
然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。
而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%203_5.jpg" width="500">
</div><br>

<ul>
<li>对于开启 HugePages 的操作系统，父进程申请内存时阻塞的概率将会大大提高，Hugepages 在实际使用 Redis 并需要持久化时是建议关掉的。</li>
</ul>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>极客时间 - 《Redis核心技术与实战》 学习笔记 4</title>
    <url>/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-4/</url>
    <content><![CDATA[<h3 id="内存快照：宕机后，Redis如何实现快速恢复？"><a href="#内存快照：宕机后，Redis如何实现快速恢复？" class="headerlink" title="内存快照：宕机后，Redis如何实现快速恢复？"></a>内存快照：宕机后，Redis如何实现快速恢复？</h3><hr>
<ul>
<li>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
save：在主线程中执行，会导致阻塞；
bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。
</pre>

<ul>
<li>Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。</li>
</ul>
<span id="more"></span>

<pre style="font-size:0.9em; color:#666666;">
简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。<br>
bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。<br>
此时，如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。<br>
但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。<br>
然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%204_1.jpg" width="500">
</div><br>

<ul>
<li>如果频繁地执行全量快照，也会带来两方面的开销。</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，
前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。<br>
另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。<br>
虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，
而且主线程的内存越大，阻塞时间越长。<br>
如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。
</pre>

<ul>
<li>Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。<br>
这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。<br>
而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，
因此，就不会出现文件过大的情况了，也可以避免重写开销。<br>
如下图所示，T1 和 T2 时刻的修改，用 AOF 日志记录，
等到第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%204_2.jpg" width="500">
</div><br>

<ul>
<li>RDB 优势在于，可以快速恢复数据库，也就是只需要把 RDB 文件直接读入内存，避免了 AOF 需要顺序、逐一重新执行操作命令带来的低效性能问题。缺点是频繁快照很耗资源<br>
<br></li>
<li>三点建议</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
1. 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；<br>
2. 如果允许分钟级别的数据丢失，可以只使用 RDB；<br>
3. 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。
</pre>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>递归反转栈</title>
    <url>/%E9%80%92%E5%BD%92%E5%8F%8D%E8%BD%AC%E6%A0%88/</url>
    <content><![CDATA[<h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>翻转栈的所有元素，例如输入栈 {1,2,3,4,5}，其中 1 处在栈顶，翻转之后的栈为 {5,4,3,2,1}，其中，5 处在栈顶，注意使用递归</p>
<h3 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h3><p>递归算法不需要考虑中间过程，上一层的递归可以直接使用下一层的递归结果，即假设下一层已经完成了我们的要求就行了，最后只需要考虑最后一层递归退出的条件就行了</p>
<span id="more"></span>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E9%80%92%E5%BD%92%E5%8F%8D%E8%BD%AC%E6%A0%88.png" width="2000">
</div><br>

<p>递归函数结束的条件：是当栈为空或者栈里只有一个元素的时候，return。</p>
<h3 id="解题代码"><a href="#解题代码" class="headerlink" title="解题代码"></a>解题代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reverse_stack</span>(<span class="params">s</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> s:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(s) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    temp1 = s.pop()</span><br><span class="line">    reverse_stack(s)</span><br><span class="line">    temp2 = s.pop()</span><br><span class="line">    reverse_stack(s)</span><br><span class="line">    s.append(temp1)</span><br><span class="line">    reverse_stack(s)</span><br><span class="line">    s.append(temp2)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    stack = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">    reverse_stack(stack)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;翻转后出栈的顺序为：&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(stack)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>DS&amp;A</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DS&amp;A</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis 面试知识点总结（上）</title>
    <url>/Redis-%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
    <content><![CDATA[<h1 id="Redis-和-Memecache-的区别是什么？"><a href="#Redis-和-Memecache-的区别是什么？" class="headerlink" title="Redis 和 Memecache 的区别是什么？"></a>Redis 和 Memecache 的区别是什么？</h1><pre><code>1. Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memecache 支持简单的数据类型 String
2. Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memecache 把数据全部存在内存之中
3. Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的
4. Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型
</code></pre>
<h1 id="Redis-常见数据结构以及使用场景分析？"><a href="#Redis-常见数据结构以及使用场景分析？" class="headerlink" title="Redis 常见数据结构以及使用场景分析？"></a>Redis 常见数据结构以及使用场景分析？</h1><pre><code>1. String 字符串
   字符串类型是 Redis 最基础的数据结构，首先键都是字符串类型，而且其他几种数据结构都是在字符串类型基础上构建的。
   常用在缓存、计数、共享 Session、限速等。
2. Hash 哈希
   在 Redis 中，哈希类型是指键值本身又是一个键值对结构，形如 value=&#123;&#123;field1，value1&#125;，...&#123;fieldN，valueN&#125;&#125;。
   哈希可以用来存放用户信息，比如实现购物车。
3. List 列表
   列表（list）类型是用来存储多个有序的字符串。
   可以做简单的消息队列的功能。另外，可以利用 lrange 命令，做基于 Redis 的分页功能，性能极佳，用户体验好。
4. Set 集合
   集合（set）类型也是用来保存多个的字符串元素，但集合中不允许有重复元素，并且集合中的元素是无序的，不能通过索引下标获取元素。
   利用 Set 的交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。
5. Sorted Set 有序集合
   Sorted Set 多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。
   可以做排行榜应用，取 TOP N 操作

除此之外还有 3 个高级数据结构
1. Bitmaps bitmaps 应用于信息状态统计
2. HyperLogLog 应用于基数统计
3. GEO 应用于地理位置计算
</code></pre>
<span id="more"></span>

<h1 id="Redis-String-的实现原理"><a href="#Redis-String-的实现原理" class="headerlink" title="Redis String 的实现原理"></a>Redis String 的实现原理</h1><pre><code>Redis 内部 String 类型采用 SDS（simple dynamic string）表示
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct sdshdr &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; buf 已占用长度</span><br><span class="line">    int len;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; buf 剩余可用长度</span><br><span class="line">    int free;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 实际保存字符串数据的地方</span><br><span class="line">    char buf[];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
对比 C 字符串， SDS 有以下特性：
    1. 可以高效地执行长度计算（strlen） // 直接取 len 字段
    2. 防止 buf 存储内容溢出的问题 // 首先判断 free 字段是否足够
    3. 可以高效地执行追加操作（append） // 通过预分配空间，free 字段
    4. 二进制安全 // 不以 \0 做为结尾标识
</code></pre>
<h1 id="Redis-List-的实现原理"><a href="#Redis-List-的实现原理" class="headerlink" title="Redis List 的实现原理"></a>Redis List 的实现原理</h1><pre><code>在 Redis 3.2 之前，List 底层采用了 ZipList 和 LinkedList 实现的，在 3.2 之后，List 底层采用了 QuickList。
Redis 3.2 之前，初始化的 List 使用的 ZipList，当以下两个条件任意一个不满足时，则会被转换成 LinkedList：
    1. List 中存储的每个元素的长度小于 64byte（可以通过配置文件修改）
    2. 元素个数小于 512（可以通过配置文件修改）

ZipList 为节省内存而设计，内存是连续的
没有维护双向指针：prev next，而是存储上一个 entry（可以理解为一个数据）的长度和 当前 entry 的长度，通过长度推算下一个元素在什么地方。
最大的缺点是是连锁更新问题，以时间换空间。
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（上）/Redis-ZipList.png'>
</p>

<table>
<thead>
<tr>
<th align="center">属性</th>
<th align="center">类型</th>
<th align="center">长度</th>
<th align="center">用途</th>
</tr>
</thead>
<tbody><tr>
<td align="center">zlbytes</td>
<td align="center">uint_32t</td>
<td align="center">4B</td>
<td align="center"><strong>记录整个压缩列表占用的内存字节数</strong>：在对压缩列表进行内存重分配， 或者计算 zlend的位置时使用</td>
</tr>
<tr>
<td align="center">zltail</td>
<td align="center">uint_32t</td>
<td align="center">4B</td>
<td align="center"><strong>记录压缩列表表尾节点距离压缩列表的起始地址有多少字节</strong>：通过这个偏移量，程序无须遍历整个压缩列表就可以确定表尾节点的地址</td>
</tr>
<tr>
<td align="center">zllen</td>
<td align="center">uint_16t</td>
<td align="center">2B</td>
<td align="center"><strong>记录了压缩列表包含的节点数量</strong>： 当这个属性的值小于UINT16_ MAX （65535）时， 这个属性的值就是压缩列表包含节点的数量；当这个值等于 UINT16_MAX 时，节点的真实数量需要遍历整个压缩列表才能计算得出</td>
</tr>
<tr>
<td align="center">entryX</td>
<td align="center">列表节点</td>
<td align="center">不定</td>
<td align="center">压缩列表包含的各个节点，<strong>节点的长度由节点保存的内容决定</strong></td>
</tr>
<tr>
<td align="center">zlend</td>
<td align="center">uint_8t</td>
<td align="center">1B</td>
<td align="center">特殊值 0xFF （十进制 255 ），<strong>用于标记压缩列表的末端</strong></td>
</tr>
</tbody></table>
<pre><code>LinkedList 是由一系列不连续的内存块通过指针连接起来的双向链表。
缺点是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针。
其次，它的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（上）/Redis-LinkedList.png'>
</p>

<pre><code>QuickList 是一个 ZipList 组成的双向链表。
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（上）/Redis-QuickList.png'>
</p>

<h1 id="Redis-Hash-的实现原理"><a href="#Redis-Hash-的实现原理" class="headerlink" title="Redis Hash 的实现原理"></a>Redis Hash 的实现原理</h1><pre><code>参考：
    1. [渐进式 rehash](http://redisbook.com/preview/dict/incremental_rehashing.html)

Redis 的哈希对象的底层存储可以使用 ZipList 和 HashTable。
当 Hash 对象可以同时满足一下两个条件时，哈希对象使用 ZipList 编码：
    1. 哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节（可以通过配置文件修改）
    2. 哈希对象保存的键值对数量小于 512 个（可以通过配置文件修改）

HashTable 编码的哈希表对象底层使用字典数据结构。
Redis 解决哈希冲突的方式，是链式哈希。
这里存在一个问题，哈希冲突链上的元素只能通过指针逐一查找再操作。
如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长。
所以，Redis 会对哈希表做 rehash 操作。

渐进式的 rehash
rehash 使用两个哈希表 1 和哈希表 2。
随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步：
  1. 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；
  2. 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；
  3. 释放哈希表 1 的空间。
在第 2 步 Redis 不是一次性把全部数据 rehash 成功，这样会导致 Redis 对外服务停止，Redis 内部为了处理这种情况采用渐进式的 rehash。
Redis 将所有的 rehash 的操作分成多步进行，直到都 rehash 完成，
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（上）/Redis-HashTable.jpg'>
</p>

<h1 id="Redis-Set-的实现原理"><a href="#Redis-Set-的实现原理" class="headerlink" title="Redis Set 的实现原理"></a>Redis Set 的实现原理</h1><pre><code>Set 集合采用 intset（整数集合）和 HashTable 两种方式来实现，当满足以下两个条件的时候，采用 intset 实现，
一旦有一个条件不满足时则采用 HashTable 来实现：
    1. Set 集合中的所有元素都为整数
    2. Set 集合中的元素个数不大于 512（可以通过配置文件修改）
</code></pre>
<h1 id="Redis-Sorted-Set-的实现原理"><a href="#Redis-Sorted-Set-的实现原理" class="headerlink" title="Redis Sorted Set 的实现原理"></a>Redis Sorted Set 的实现原理</h1><pre><code>参考：
    1. [Redis 为什么用跳表而不用平衡树？](https://juejin.cn/post/6844903446475177998)

Zset 底层同样采用了两种方式来实现，分别是 ZipList 和 SkipList。当同时满足以下两个条件时，采用 ZipList 实现；反之采用 SkipList 实现：
    1. Zset 中保存的元素个数小于 128（可以通过配置文件修改）
    2. Zset 中保存的所有元素长度小于 64byte（可以通过配置文件修改）

采用 ZipList 的实现原理
    和 List 的底层实现有些相似，对于 Zset 不同的是，其存储是以键值对的方式依次排列，键存储的是实际 value，值存储的是 value 对应的分值。

采用 SkipList 的实现原理
    SkipList 编码的 Zset 底层为一个被称为 zset 的结构体，这个结构体中包含一个字典和一个跳跃表。
    跳跃表按 score 从小到大保存所有集合元素，查找时间复杂度为平均 O(logN)，最坏 O(N) 。
    字典保存从 member 到 score 的映射，这样就可以用 O(1)​ 的复杂度来查找 member 对应的 score 值。
    跳表是一种并联的链表，它在链表的基础上增加了跳跃功能，正是这个跳跃的功能，使得在查找元素时，跳表能够提供 O(logN) 的时间复杂度。
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（上）/Redis-SkipList.jpg'>
</p>

<pre><code>为什么用的跳表不是红黑树?
    根据作者的原话：
    1. 跳表使用的内存不是固定的，可以通过调整参数，使占用的内存低于 btree
    2. Zset 通常是 Zrange 或 Zrevrange 的操作，跳表至少与其他类型的平衡树性能一样好
    3. 跳表实现简单
</code></pre>
<h1 id="Redis-压缩采用什么算法"><a href="#Redis-压缩采用什么算法" class="headerlink" title="Redis 压缩采用什么算法?"></a>Redis 压缩采用什么算法?</h1><pre><code>对 ziplist 使用 LZF 算法进行压缩，可以选择压缩深度。
</code></pre>
<h1 id="Redis-中的-Bitmaps"><a href="#Redis-中的-Bitmaps" class="headerlink" title="Redis 中的 Bitmaps"></a>Redis 中的 Bitmaps</h1><pre><code>bitmaps 不是一个真实的数据结构。而是 String 类型上的一组面向 bit 操作的集合。
常用命令：
    setbit key offset value
    getbit key offset
场景举例：
    统计活跃用户（用户登陆情况）
        使用日期作为 key，然后用户 id 为 offset，如果当日活跃过就设置为 1
    统计每天某一部电影是否被点播 统计每天有多少部电影被点播 统计每周/月/年有多少部电影被点播 统计年度哪部电影没有被点播
        日期作为 key，然后电影 id 为 offset，如果点播过就设置为 1
</code></pre>
<h1 id="Redis-中的-HyperLogLog"><a href="#Redis-中的-HyperLogLog" class="headerlink" title="Redis 中的 HyperLogLog"></a>Redis 中的 HyperLogLog</h1><pre><code>Redis HyperLogLog 是用来做基数统计的算法，优点是在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。
但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。

比如实现 统计 APP 或网页的一个页面，每天有多少用户点击进入的次数，同一个用户的反复点击进入记为 1 次。
命令有：
    PFADD key element [element ...]
        添加指定元素到 HyperLogLog 中。
    PFCOUNT key [key ...]
        返回给定 HyperLogLog 的基数估算值。
    PFMERGE destkey sourcekey [sourcekey ...]
        将多个 HyperLogLog 合并为一个 HyperLogLog
</code></pre>
<h1 id="Redis-客户端和服务器之间通信才用什么协议？"><a href="#Redis-客户端和服务器之间通信才用什么协议？" class="headerlink" title="Redis 客户端和服务器之间通信才用什么协议？"></a>Redis 客户端和服务器之间通信才用什么协议？</h1><pre><code>Redis 客户端使用基于 TCP 的 RESP（Redis 的序列化协议，Redis Serialization Protocol）协议与 Redis 的服务器端进行通信。
类型通过首个字节区分（+,-,:,$,*），每一部分结束时，Redis 统一使用“\r\n”表示结束。
</code></pre>
<h1 id="Redis-过期策略"><a href="#Redis-过期策略" class="headerlink" title="Redis 过期策略"></a>Redis 过期策略</h1><pre><code>1. 定期删除，Redis 默认每隔 100ms 检查，是否有过期的 key，有过期 key 则删除。
   需要说明的是，Redis 不是每隔 100ms 将所有的 key 检查一次，而是随机抽取进行检查(如果每隔 100ms，全部 key 进行检查，Redis 岂不是卡死)。
   因此，如果只采用定期删除策略，会导致很多 key 到时间没有删除。
2. 惰性删除，也就是说在你获取某个 key 的时候，Redis 会检查一下，这个 key 如果设置了过期时间那么是否过期，如果过期了此时就会删除。

过期策略存在的问题，由于 Redis 定期删除是随机抽取检查，不可能扫描清除掉所有过期的 key 并删除，某些 key 由于未被请求，惰性删除也未触发。
这样 Redis 的内存占用会越来越高，此时就需要内存淘汰机制。
</code></pre>
<h1 id="Redis-内存淘汰机制"><a href="#Redis-内存淘汰机制" class="headerlink" title="Redis 内存淘汰机制"></a>Redis 内存淘汰机制</h1><pre><code>- no-eviction：默认策略，不淘汰数据；大部分写命令都将返回错误（DEL 等少数除外）
- allkeys-lru：从所有数据中根据 LRU 算法挑选数据淘汰
- volatile-lru：从设置了过期时间的数据中根据 LRU 算法挑选数据淘汰
- allkeys-random：从所有数据中随机挑选数据淘汰
- volatile-random：从设置了过期时间的数据中随机挑选数据淘汰
- volatile-ttl：从设置了过期时间的数据中，挑选越早过期的数据进行删除
- allkeys-lfu：从所有数据中根据 LFU 算法挑选数据淘汰（4.0 及以上版本可用）
- volatile-lfu：从设置了过期时间的数据中根据 LFU 算法挑选数据淘汰（4.0 及以上版本可用）
</code></pre>
<h1 id="LRU-与-LFU-的区别"><a href="#LRU-与-LFU-的区别" class="headerlink" title="LRU 与 LFU 的区别"></a>LRU 与 LFU 的区别</h1><pre><code>LFU：Least Recently Used，最近最少使用
LFU：Least Frequently Used，使用频率最少的（最不经常使用的）
如果一条数据仅仅是突然被访问（有可能后续将不再访问），在 LRU 算法下，此数据将被定义为热数据，最晚被淘汰。
但实际生产环境下，我们很多时候需要计算的是一段时间下 key 的访问频率，淘汰此时间段内的冷数据。

LFU 算法相比 LRU，在某些情况下可以提升 数据命中率，使用频率更多的数据将更容易被保留。
</code></pre>
<table>
<thead>
<tr>
<th>对比项</th>
<th>近似LRU算法</th>
<th>LFU 算法</th>
</tr>
</thead>
<tbody><tr>
<td>最先过期的数据</td>
<td>最近未被访问的</td>
<td>最近一段时间访问的最少的</td>
</tr>
<tr>
<td>适用场景</td>
<td>数据被连续访问场景</td>
<td>数据在一段时间内被连续访问</td>
</tr>
<tr>
<td>缺点</td>
<td>新增 key 将占据缓存</td>
<td>历史访问次数超大的 key 淘汰速度取决于 lfu-decay-time</td>
</tr>
</tbody></table>
<h1 id="Redis-的-LRU-实现"><a href="#Redis-的-LRU-实现" class="headerlink" title="Redis 的 LRU 实现"></a>Redis 的 LRU 实现</h1><pre><code>Redis 中的 LRU 与常规的 LRU 实现并不相同，常规 LRU 会准确的淘汰掉队头的元素，但是 Redis 的 LRU 并不维护队列，
只是根据配置的策略要么从所有的 key 中随机选择 N 个（N 可以配置）要么从所有的设置了过期时间的 key 中选出 N 个键，
然后再从这 N 个键中选出最久没有使用的一个 key 进行淘汰。

为什么要使用近似 LRU？
1. 性能问题，由于近似 LRU 算法只是最多随机采样 N 个 key 并对其进行排序，如果精准需要对所有 key 进行排序，这样近似 LRU 性能更高
2. 内存占用问题，Redis 对内存要求很高，会尽量降低内存使用率，如果是抽样排序可以有效降低内存的占用
3. 实际效果基本相等，如果请求符合长尾法则，那么真实 LRU 与 Redis LRU 之间表现基本无差异
</code></pre>
<h1 id="如何保证-Redis-中存放的都是热点数据"><a href="#如何保证-Redis-中存放的都是热点数据" class="headerlink" title="如何保证 Redis 中存放的都是热点数据"></a>如何保证 Redis 中存放的都是热点数据</h1><pre><code>限定 Redis 占用的内存，Redis 会根据自身数据淘汰策略，留下热数据到内存。
所以，计算一下热点数据大约占用的内存，然后设置一下 Redis 内存限制，并根据业务场景修改淘汰策略
</code></pre>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis 面试知识点总结（下）</title>
    <url>/Redis-%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%8B%EF%BC%89/</url>
    <content><![CDATA[<h1 id="Redis-事务机制"><a href="#Redis-事务机制" class="headerlink" title="Redis 事务机制"></a>Redis 事务机制</h1><pre><code>1. multi —— 开启事务
2.命令入队列
    之后所有的命令都会放入事务队列中，并不会立刻执行。
    如果客户端发送的命令为 EXEC，DISCARD 的其中一个，服务器会立刻执行这个命令。
    对于其它命令，服务器并不会立刻执行，而是将这个命令放入一个事务队列中，然后向客户端返回 QUEUED 回复
3. exec —— 执行事务
4. DISCARD —— 放弃执行

Redis 的事务机制可以保证一致性和隔离性（watch 机制）。
持久性取决于是否开启持久化以及持久化机制，极端情况下还是无法保证。
原子性的情况比较复杂：
    1. 命令入队时就报错，会放弃事务执行，保证原子性
    2. 命令入队时没报错，实际执行时报错，不保证原子性
    3. EXEC 命令执行时实例故障，如果开启了 AOF 日志，可以保证原子性
      （使用 redis-check-aof 工具检查 AOF 日志文件，这个工具可以把未完成的事务操作从 AOF 文件中去除。
       使用 AOF 恢复实例后，事务操作不会再被执行，从而保证原子性。
    只有当事务中使用的命令语法有误时，原子性得不到保证，在其它情况下，事务都可以原子性执行。
</code></pre>
<span id="more"></span>

<h1 id="Redis-主从同步机制"><a href="#Redis-主从同步机制" class="headerlink" title="Redis 主从同步机制"></a>Redis 主从同步机制</h1><pre><code>主从模式是最简单的实现高可用的方案，核心就是主从同步。主从同步的原理如下：

1. slave 发送 sync 命令到 master
2. master 收到 sync 之后，执行 bgsave，生成 RDB 全量文件
3. master 把 slave 的写命令记录到缓存
4. bgsave 执行完毕之后，发送 RDB 文件到 slave，slave 执行
5. master 发送缓存中的写命令到 slave，slave 执行
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（下）/Redis-主从同步机制.jpg'>
</p>

<pre><code>上面写的命令是 sync，但是在 Redis 2.8 版本之后已经使用 psync 来替代 sync 了，
原因是 sync 命令非常消耗系统资源，而 psync 的效率更高（增量同步）。
主从模式下，当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这需要人工干预，费事费力，还会造成一段时间内服务不可用。
这种方式并不推荐，实际生产中，优先考虑哨兵模式。

优缺点：
   优点：
       1. 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离
       2. Slave 同样可以接受其他 Slaves 的连接和同步请求，这样可以有效地分载 Master 的同步压力
   缺点：
       1. Redis 不具备自动容错和恢复功能，主从不可以自动切换
       2. 主机宕机，宕机前有部分数据未能及时同步到从机，切换 IP 后还会引入数据不一致的问题，降低了系统的可用性
       3. 较难支持在线扩容
</code></pre>
<h1 id="Redis-哨兵"><a href="#Redis-哨兵" class="headerlink" title="Redis 哨兵"></a>Redis 哨兵</h1><pre><code>哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。
哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。

监控：
   哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。
   如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。
   如果检测的是从库，那么，哨兵简单地把它标记为“主观下线”就行了。
   但是，如果检测的是主库，那么，哨兵还不能简单地把它标记为“主观下线”，开启主从切换，因为主从切换开销很大，防止误判。
   只有 N/2 + 1 的哨兵实例，都判断主库已经“主观下线”了，主库才会被标记为“客观下线”，
选主：
   主库挂了以后，在多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉。
   然后，再按照一定的规则，给剩下的从库逐个打分，将得分最高的从库选为新主库。
   筛选过程除了要检查从库的当前在线状态，还要判断它之前的网络连接状态。
   在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，就可以认为主从节点断连了。
   如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库。
   打分过程分别按照三个规则依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库 ID 号。
通知：
   在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。
   同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。
   客户端和哨兵之间的事件通知通过哨兵自身的 pub/sub 功能实现
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（下）/Redis-哨兵.jpg'>
</p>

<pre><code>优缺点：
   优点：
       1. 主从模式的所有优点
       2. 主从可以自动切换，系统更健壮，可用性更高
   缺点：
       除了支持主从自动切换外的主从模式的所有缺点
</code></pre>
<h1 id="Redis-集群"><a href="#Redis-集群" class="headerlink" title="Redis 集群"></a>Redis 集群</h1><pre><code>从 Redis 3.0 开始，官方提供了一个名为 Redis Cluster 的方案，用于实现切片集群。
Redis Cluster 采用哈希槽（Hash Slot），来处理数据和实例之间的映射关系。

在 Redis Cluster 中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。

为什么采用 16384？

    1. 在 Redis 节点发送心跳包时需要把所有的槽放到这个心跳包里，以便让节点知道当前集群信息，16384=16k，
       在发送心跳包时使用 char 进行 bitmap 压缩后是 2k（2 * 8 (8 bit) * 1024(1k) = 16K），也就是说使用 2k 的空间创建了 16k 的槽数。
       虽然使用 CRC16 算法最多可以分配 65535（2^16-1）个槽位，65535=65k，压缩后就是 8k（8 * 8 (8 bit) * 1024(1k) =65K），
       也就是说需要需要 8k 的心跳包，作者认为这样做不太值得
    2. 并且一般情况下一个 Redis 集群不会有超过 1000 个 master 节点，所以 16k 的槽位是个比较合适的选择

具体的映射过程分为两大步：
    1. 首先根据键值对的 key，按照 CRC16 算法计算一个 16bit 的值
    2. 然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽

哈希槽和实例的对应：
    部署 Redis Cluster 时，可以使用 cluster create 命令创建集群，此时，Redis 会自动把这些槽平均分布在集群实例上。
    也可以使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用 cluster addslots 命令，指定每个实例上的哈希槽个数。
    当 16384 个 slot 都有节点在处理时，集群处于上线状态，反之只要有一个 slot 没有得到处理都会处理下线状态。

客户端如何定位数据？
    当客户端请求键值对时，会先计算键所对应的哈希槽，然后给相应的实例发送请求。
    在定位键值对数据时，它所处的哈希槽是可以通过计算得到的，这个计算可以在客户端发送请求时来执行。
    知道哈希槽后，客户端如何知道哈希槽分布在哪个实例上？
        Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。
        当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。
        客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。

Redis 集群间通信参用什么协议？
    gossip 协议通信

在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：
    1. 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽
    2. 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。
此时，实例可以通过相互传递消息，获得最新的哈希槽分配信息，但是，客户端是无法主动感知这些变化的。
这就会导致，它缓存的分配信息和最新的分配信息不一致。

Redis Cluster 采取重定向机制解决这个问题。
当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有对应的哈希槽，会给客户端返回 MOVED 响应结果，
结果中包含了新实例的访问地址。
如果此时，旧实例中的数据只有一部分迁移到了新实例，还有部分数据没有迁移，客户端会收到一条 ASK 报错信息。
代表这个哈希槽正在迁移。此时，客户端需要先给新实例发送一个 ASKING 命令（代表破例执行关于槽的命令一次）。
然后，客户端再向新实例发送 GET 命令，以读取数据。

故障发现和转移：
    如果节点 A 向节点 B 发送 ping 消息，节点 B 没有在规定的时间内响应 pong，那么节点 A 会标记节点 B 为 pfail 疑似下线状态，
    同时把 B 的状态通过消息的形式发送给其他节点，如果超过半数以上的节点都标记 B 为 pfail 状态，B 就会被标记为 fail 下线状态，
    此时将会发生故障转移。
    优先从复制数据较多的从节点选择一个成为主节点，并且接管下线节点的 slot，整个过程和哨兵非常类似，都是基于 Raft 协议做选举。
    但是如果下线的主节点没有从节点，整个集群还是处于不可用的状态。

Redis Cluster 并不能保证数据的强一致性，在实际中集群在特定的条件下可能会丢失写操作，原因是集群采用异步复制。
</code></pre>
<h1 id="Redis-中，sentinel-和-cluster-的区别和适用场景是什么？"><a href="#Redis-中，sentinel-和-cluster-的区别和适用场景是什么？" class="headerlink" title="Redis 中，sentinel 和 cluster 的区别和适用场景是什么？"></a>Redis 中，sentinel 和 cluster 的区别和适用场景是什么？</h1><pre><code>哨兵是解决了 Redis 的高可用，而 cluster 则是解决了 Redis 的高并发。
</code></pre>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis 面试知识点总结（中）</title>
    <url>/Redis-%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%AD%EF%BC%89/</url>
    <content><![CDATA[<h1 id="热点-key-问题"><a href="#热点-key-问题" class="headerlink" title="热点 key 问题"></a>热点 key 问题</h1><pre><code>热点 key 问题就是，突然有几十万甚至更大的请求去访问 Redis 上的某个特定 key。
那么，这样会造成流量过于集中，达到 Redis 单实例瓶颈（一般是 10W OPS 级别），或者物理网卡上限，从而导致这台 Redis 的服务器 Hold 不住。

怎么发现热 key？
1. 凭借业务经验，进行预估哪些是热 key
2. 在客户端进行收集
3. 在 Proxy 层做收集
4. 用 Redis 自带命令
    4.1 monitor 命令，该命令可以实时抓取出 Redis 服务器接收到的命令，然后写代码统计出热 key 是啥。
        当然，也有现成的分析工具可以给你使用，比如 redis-faina。但是该命令在高并发的条件下，有内存增暴增的隐患，还会降低 Redis 的性能。
    4.2 hotkeys 参数（必须配合 LFU），Redis 4.0.3 提供了 redis-cli 的热点 key 发现功能，执行 redis-cli 时加上 –hotkeys 选项即可。
        但是该参数在执行的时候，如果 key 比较多，执行起来比较慢。
5. 自己抓包评估，Redis 客户端使用 TCP 协议与服务端进行交互，通信协议采用的是 RESP。自己写程序监听端口，按照 RESP 协议解析数据，进行分析。
   缺点就是开发成本高，维护困难，有丢包可能性。

如何解决？
1. 设置二级缓存（推荐）
2. 利用分片算法的特性，对 key 进行打散处理
   hot key 之所以是 hot key，是因为它只有一个 key，落地到一个实例上。
   可以给 hot key 加上前缀或者后缀，把一个 hotkey 的数量经过分片分布到不同的实例上，将访问量均摊到所有实例。
</code></pre>
<span id="more"></span>

<h1 id="大-key-问题"><a href="#大-key-问题" class="headerlink" title="大 key 问题"></a>大 key 问题</h1><pre><code>由于 Redis 主线程为单线程模型，大 key 也会带来一些问题，如：
1. 集群模式在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 高。
2. 大 key 相关的删除或者自动过期时，会出现 qps 突降或者突升的情况，极端情况下，会造成主从复制异常，Redis 服务阻塞无法响应请求。

怎么发现大 key？
- Redis 4.0 之前的大 key 的发现与删除方法
  1. redis-rdb-tools 工具。Redis 实例上执行 bgsave，然后对 dump 出来的 rdb 文件进行分析，找到其中的大 key
  2. redis-cli --bigkeys 命令。可以找到某个实例 5 种数据类型（string、hash、list、set、zset）的最大 key
  3. 自定义的扫描脚本，以 Python 脚本居多，方法与 redis-cli --bigkeys 类似
- Redis 4.0 之后的大 key 的发现与删除方法
  Redis 4.0 引入了 memory usage 命令和 lazyfree 机制，不管是对大 key 的发现，还是解决大 key 删除或者过期造成的阻塞问题都有明显的提升。
  memory usage 可以用较小的代价去获取所有 key 的内存大小。

如何删除？
- Redis 4.0 之前的大 key 的发现与删除方法
  分解删除操作，把 大的 key 分解成小部分逐渐删除：
  list: 逐步 ltrim;
  zset: 逐步 zremrangebyscore
  hset: hscan，然后 hdel 删除
  set: sscan，然后 srem 删除
- Redis 4.0 之后的大 key 的发现与删除方法
  删除大key： lazyfree 机制
  unlink 命令，代替 DEL 命令，会把对应的大 key 放到 BIO_LAZY_FREE 后台线程任务队列，然后在后台异步删除。
</code></pre>
<h1 id="如何保证缓存与数据库双写时的数据一致性？"><a href="#如何保证缓存与数据库双写时的数据一致性？" class="headerlink" title="如何保证缓存与数据库双写时的数据一致性？"></a>如何保证缓存与数据库双写时的数据一致性？</h1><pre><code>对于缓存和数据库的操作，主要有以下两种方式。
1. 先删缓存，再更新数据库
先删除缓存，数据库还没有更新成功，此时如果读取缓存，缓存不存在，去数据库中读取到的是旧值，缓存不一致发生。
解决方案：
    延时双删
    延时双删的方案的思路是，为了避免更新数据库的时候，其他线程从缓存中读取不到数据，
    就在更新完数据库之后，再 sleep 一段时间，然后再次删除缓存。
    sleep 的时间要对业务读写缓存的时间做出评估，sleep 时间大于读写缓存的时间即可。
2. 先更新数据库，再删除缓存
更新数据库成功，如果删除缓存失败或者还没有来得及删除，那么，其他线程从缓存中读取到的就是旧值，还是会发生不一致。
解决方案：
    消息队列
    先更新数据库，成功后往消息队列发消息，消费到消息后再删除缓存，借助消息队列的重试机制来实现，达到最终一致性的效果。
    缺点：引入消息中间件之后，问题更复杂，就算更新数据库和删除缓存都没有发生问题，
          消息的延迟也会带来短暂的不一致性，不过这个延迟相对来说还是可以接受的

    进阶版消息队列
    为了解决缓存一致性的问题单独引入一个消息队列，太复杂。
    其实，一般大公司本身都会有监听 binlog 消息的消息队列存在，主要是为了做一些核对的工作。
    这样，我们可以借助监听 binlog 的消息队列来做删除缓存的操作。
    这样做的好处是，不用你自己引入，侵入到你的业务代码中，中间件帮你做了解耦，同时，中间件的这个东西本身就保证了高可用。
    当然，这样消息延迟的问题依然存在，但是相比单纯引入消息队列的做法更好一点。

其他解决方案：
    设置缓存过期时间
    每次放入缓存的时候，设置一个过期时间，比如 5 分钟，以后的操作只修改数据库，不操作缓存，等待缓存超时后从数据库重新读取。
    如果对于一致性要求不是很高的情况，可以采用这种方案。

为什么是删除，而不是更新缓存？
    以先更新数据库，再删除缓存来举例。
    如果是更新的话，那就是先更新数据库，再更新缓存。
    举个例子：
        如果数据库 1h 内更新了 1000 次，那么缓存也要更新 1000 次，
        但是这个缓存可能在 1h 内只被读取了 1 次，那么这 1000 次的更新没有必要
        反过来，如果是删除的话，就算数据库更新了 1000 次，那么也只是做了 1 次缓存删除，
        只有当缓存真正被读取的时候才去数据库加载。
</code></pre>
<h1 id="Redis-如何实现异步队列？"><a href="#Redis-如何实现异步队列？" class="headerlink" title="Redis 如何实现异步队列？"></a>Redis 如何实现异步队列？</h1><pre><code>一般使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep 一会再重试。
如果不用 sleep 呢？list 还有个指令叫 blpop，在没有消息的时候，它会阻塞住直到消息到来。

能不能生产一次消费多次？
使用 pub/sub 主题订阅者模式，可以实现 1:N 的消息队列。
pub/sub 有什么缺点？
在消费者下线的情况下，生产的消息会丢失，改为使用专业的消息队列如 RocketMQ 等。
</code></pre>
<h1 id="Redis-如何实现延时队列？"><a href="#Redis-如何实现延时队列？" class="headerlink" title="Redis 如何实现延时队列？"></a>Redis 如何实现延时队列？</h1><pre><code>使用 sortedset，拿时间戳作为 score，消息内容作为 key 调用 zadd 来生产消息，消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理。
</code></pre>
<h1 id="Pipeline-有什么好处，为什么要用-Pipeline？"><a href="#Pipeline-有什么好处，为什么要用-Pipeline？" class="headerlink" title="Pipeline 有什么好处，为什么要用 Pipeline？"></a>Pipeline 有什么好处，为什么要用 Pipeline？</h1><pre><code>可以将多次 IO 往返的时间缩减为一次，并且减少 Redis 中的系统调用。
</code></pre>
<h1 id="Redis-如何实现分布式锁？"><a href="#Redis-如何实现分布式锁？" class="headerlink" title="Redis 如何实现分布式锁？"></a>Redis 如何实现分布式锁？</h1><pre><code>参考：
    1. [分布式锁的实现之 redis 篇](https://xiaomi-info.github.io/2019/12/17/redis-distributed-lock/)

Redis 锁主要利用 Redis 的 setnx 命令。
加锁命令：SETNX key value，当键不存在时，对键进行设置操作并返回成功，否则返回失败。KEY 是锁的唯一标识，一般按业务来决定命名。
解锁命令：DEL key，通过删除键值对释放锁，以便其他线程可以通过 SETNX 命令来获取锁。
锁超时：EXPIRE key timeout, 设置 key 的超时时间，以保证即使锁没有被显式释放，锁也可以在一定时间后自动释放，避免资源被永远锁住。
问题：
    1. SETNX 和 EXPIRE 非原子性
       使用 lua 脚本

    2. 锁误解除
       如果线程 A 成功获取到了锁，并且设置了过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁；
       随后 A 执行完成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，线程 A 实际释放的线程 B 加的锁。

       通过在 value 中设置当前线程加锁的标识，在删除之前验证 key 对应的 value 判断锁是否是当前线程持有。
       可生成一个 UUID 标识当前线程，使用 lua 脚本做验证标识和解锁操作

    3. 超时解锁导致并发
       如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁，A 和 B 并发执行。

       A、B 两个线程发生并发显然是不被允许的，一般有两种方式解决该问题：
           1. 将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。
           2. 为获取锁的线程增加守护线程，为将要过期但未释放的锁增加有效时间。

    4. 不可重入
       当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的。
       如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败。
       Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时释放锁。

       Redis Hash 数据结构来实现分布式锁，既存锁的标识也对重入次数进行计数

    5. 无法等待锁释放
       上述命令执行都是立即返回的，如果客户端可以等待锁释放就无法使用。

       1. 可以通过客户端轮询的方式解决该问题，当未获取到锁时，等待一段时间重新获取锁，直到成功获取锁或等待超时。
          这种方式比较消耗服务器资源，当并发量比较大时，会影响服务器的效率。
       2. 另一种方式是使用 Redis 的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。

    6. 集群
       主备切换、集群脑裂时会造成问题，使用 RedLock 算法
</code></pre>
<h1 id="Redis-分布式锁和-ZooKeeper-区别？"><a href="#Redis-分布式锁和-ZooKeeper-区别？" class="headerlink" title="Redis 分布式锁和 ZooKeeper 区别？"></a>Redis 分布式锁和 ZooKeeper 区别？</h1><pre><code>1. 实现难度上：Zookeeper &gt;= Redis
   对于直接操纵底层 API 来说，实现难度都是差不多的，都需要考虑很多边界场景。但由于 Zk 的 ZNode 天然具有锁的属性，很简单。
   Redis 需要考虑太多异常场景，比如锁超时、锁的高可用等，实现难度较大。

2. 服务端性能：Redis &gt; Zookeeper
   Zk 基于 Zab 协议，需要一半的节点 ACK，才算写入成功，吞吐量较低。如果频繁加锁、释放锁，服务端集群压力会很大。
   Redis 基于内存，只写 Master 就算成功，吞吐量高，Redis 服务器压力小。

3. 客户端性能：Zookeeper &gt; Redis
   Zk 由于有通知机制，获取锁的过程，添加一个监听器就可以了。避免了轮询，性能消耗较小。
   Redis 并没有通知机制，它只能使用类似 CAS 的轮询方式去争抢锁，较多空转，会对客户端造成压力。

4. 可靠性：Zookeeper &gt; Redis
   Zookeeper 就是为协调而生的，有严格的 Zab 协议控制数据的一致性，锁模型健壮。
   Redis 追求吞吐，可靠性上稍逊一筹。即使使用了 Redlock，也无法保证 100% 的健壮性，但一般的应用不会遇到极端场景，所以也被常用。
</code></pre>
<h1 id="什么是缓存击穿，怎么解决"><a href="#什么是缓存击穿，怎么解决" class="headerlink" title="什么是缓存击穿，怎么解决"></a>什么是缓存击穿，怎么解决</h1><pre><code>缓存击穿的概念就是单个 key 并发访问过高，过期时导致所有请求直接打到 DB 上.
这个和热 key 的问题比较类似，只是说的点在于过期导致请求全部打到 DB 上而已。

解决方案：
    1. 加锁更新，比如请求查询 A，发现缓存中没有，对 A 这个 key 加锁，
       同时去数据库查询数据，写入缓存，再返回给用户，这样后面的请求就可以从缓存中拿到数据了。
    2. 将过期时间组合写在 value 中，通过异步的方式不断的刷新过期时间，防止此类现象。
</code></pre>
<h1 id="什么是缓存穿透，怎么解决"><a href="#什么是缓存穿透，怎么解决" class="headerlink" title="什么是缓存穿透，怎么解决"></a>什么是缓存穿透，怎么解决</h1><pre><code>参考：
    1. [利用 Redis 的 bitmap 实现简单的布隆过滤器](https://learnku.com/articles/46442)

缓存穿透是指查询不存在缓存中的数据，每次请求都会打到 DB，就像缓存不存在一样。

解决方案：
    针对这个问题，加一层布隆过滤器。
    布隆过滤器的原理是在你存入数据的时候，会通过散列函数将它映射为一个位数组中的 K 个点，同时把他们置为 1。
    这样当用户再次来查询 A，而 A 在布隆过滤器值为 0，直接返回，就不会产生击穿请求打到 DB 了。
    使用布隆过滤器之后会有一个问题就是误判，因为它本身是一个数组，可能会有多个值落到同一个位置。
    理论上来说只要我们的数组长度够长，误判的概率就会越低，这种问题就根据实际情况来就好了。
    BloomFilter 用 Bitmap 实现，关于如何实现，可以参考 [1]
</code></pre>
<h1 id="什么是缓存雪崩，怎么解决"><a href="#什么是缓存雪崩，怎么解决" class="headerlink" title="什么是缓存雪崩，怎么解决"></a>什么是缓存雪崩，怎么解决</h1><pre><code>当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到 DB 上，这样可能导致整个系统的崩溃，称为雪崩。
雪崩和击穿、热 key 的问题不太一样，是指大规模的缓存都过期失效了。

解决方案：
    1. 针对不同 key 设置不同的过期时间，避免同时过期
    2. 限流，如果 Redis 宕机，可以限流，避免同时刻大量请求打崩 DB
    3. 二级缓存，同热 key 的方案
</code></pre>
<h1 id="Redis-并发竞争-key-问题如何解决？"><a href="#Redis-并发竞争-key-问题如何解决？" class="headerlink" title="Redis 并发竞争 key 问题如何解决？"></a>Redis 并发竞争 key 问题如何解决？</h1><pre><code>1. 分布式锁
2. 消息队列
</code></pre>
<h1 id="为什么-Redis-6-0-之后改用多线程？"><a href="#为什么-Redis-6-0-之后改用多线程？" class="headerlink" title="为什么 Redis 6.0 之后改用多线程？"></a>为什么 Redis 6.0 之后改用多线程？</h1><pre><code>Redis 使用多线程并非是完全摒弃单线程。
Redis 还是使用单线程模型来处理客户端的请求，只是使用多线程来处理数据的读写和协议解析，执行命令还是使用单线程。
这样做的目的是因为 Redis 的性能瓶颈在于网络 IO 而非 CPU，使用多线程能提升 IO 读写的效率，从而整体提高 Redis 的性能。
</code></pre>
<h1 id="Redis-哪些地方用到了多线程，哪些地方是单线程？"><a href="#Redis-哪些地方用到了多线程，哪些地方是单线程？" class="headerlink" title="Redis 哪些地方用到了多线程，哪些地方是单线程？"></a>Redis 哪些地方用到了多线程，哪些地方是单线程？</h1><pre><code>1. 接收请求参数
2. 解析请求参数
3. 请求响应，即将结果返回给client
</code></pre>
<h1 id="Redis-的持久化方式"><a href="#Redis-的持久化方式" class="headerlink" title="Redis 的持久化方式"></a>Redis 的持久化方式</h1><pre><code>Redis 的持久化主要有两大机制，即 AOF(Append Only File) 日志和 RDB(Redis DataBase) 快照。

RDB 优缺点：
    优点：
        1. RDB 是一个紧凑压缩的二进制文件，代表 Redis 在某个时间点上的数据快照。非常适用于备份，全量复制等场景。
        2. 与 AOF 格式的文件相比，RDB 文件可以更快的重启。
        3. RDB 对灾难恢复非常有用，它是一个紧凑的文件，可以更快的传输到远程服务器进行 Redis 服务恢复
    缺点：
        1. RDB 方式数据没办法做到实时/秒级持久化，因为 bgsave 每次运行都要执行 fork 操作创建子进程，属于重量级操作，频繁执行成本过高。
           只能保存某个时间间隔的数据，如果在这个期间 Redis 故障了，就会丢失一段时间的数据。

AOF 优缺点：
    优点：
        1. AOF 持久化保存的数据更加完整，即使发生了意外情况，根据配置的保存策略只会丢失短时间内的数据（每次操作保存的话不会丢失）；
        2. AOF 持久化文件，非常容易理解和解析，它是把所有 Redis 键值操作命令，以文件的方式存入了磁盘。
           即使不小心使用 flushall 命令删除了所有信息，只要使用 AOF 文件，删除最后的 flushall 命令，重启 Redis 即可恢复之前误删的数据。
    缺点：
        1. 对于相同的数据集来说，AOF 文件要大于 RDB 文件
        2. 在 Redis 负载比较高的情况下，RDB 比 AOF 性能更好
        3. 重启恢复数据时不如 RDB 速度快

Redis 4.0 之后新增混合持久化方式，混合持久化是结合了 RDB 和 AOF 的优点，在写入的时候，先把当前的数据以 RDB 的形式写入文件的开头，
再将后续的操作命令以 AOF 的格式存入文件，这样既能保证 Redis 重启时的速度，又能减低数据丢失的风险。
</code></pre>
<h1 id="Redis-AOF-日志原理"><a href="#Redis-AOF-日志原理" class="headerlink" title="Redis AOF 日志原理"></a>Redis AOF 日志原理</h1><pre><code>AOF 日志是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。
为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。
所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令。
所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。
除此之外，AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。

AOF 两个潜在的风险：
    1. 首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。
    2. 其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。
       这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而影响后续的操作。

三种写回策略：
    1. Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
    2. Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；
    3. No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。
想要获得高性能，就选择 No 策略。
如果想要得到高可靠性保证，就选择 Always 策略
如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 Everysec 策略。

AOF 重写机制：
    AOF 文件过大之后再往里面追加命令记录的话，效率会变低，如果日志文件太大，发生宕机恢复过程也会非常缓慢，所以会有 AOF 重写机制
    AOF 重写机制指的是，对过大的 AOF 文件进行重写，以此来压缩AOF文件的大小。
    具体的实现是检查当前键值数据库中的键值对，记录键值对的最终状态，
    将对某个键值对重复操作后产生的多条操作记录压缩成一条，实现压缩 AOF 文件的大小。

AOF 重写过程：
    一个拷贝，两处日志
    总结来说，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；
    然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。
    而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。
</code></pre>
<h1 id="Redis-RDB-快照"><a href="#Redis-RDB-快照" class="headerlink" title="Redis RDB 快照"></a>Redis RDB 快照</h1><pre><code>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave
    save：在主线程中执行，会导致阻塞；
    bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。

Redis 借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。
简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。
bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。
此时，如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。
但是，如果主线程要修改一块数据，那么，这块数据就会被复制一份，生成该数据的副本。
然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。

如果频繁地执行全量快照，也会带来两方面的开销：
    1. 频繁将全量数据写入磁盘，会给磁盘带来很大压力，
       多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。
    2. fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。
</code></pre>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次查找 lua-resty-mysql 库 insert_id 的 bug</title>
    <url>/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%9F%A5%E6%89%BE-lua-resty-mysql-%E5%BA%93-insert-id-%E7%9A%84-bug/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>我们公司平时业务开发使用 OpenResty，也一直使用 lua-resty-mysql 库连接 Mysql。</p>
<p>有一个业务场景，MySQL 中表的主键是自增 id，业务需要在 insert 语句之后需要拿到此次插入的自增 id 值。<br>我们一直使用 lua-resty-mysql 库（Openresty 组件中的一个）中执行 insert 语句返回的 res.insert_id 作为这个值（<strong>这样可以一次请求就拿到这个值</strong>）。</p>
<p>但是最近开始这个值变成负数，导致业务出现很多错误，于是便开始排查为什么 res.insert_id 会返回负数。</p>
<h1 id="基本猜测"><a href="#基本猜测" class="headerlink" title="基本猜测"></a>基本猜测</h1><p>首先确定 res.insert_id 这个值是负数之后，第一反应想到的是会不会 MySQL 的主键超出类型范围，导致自增 id 变成负数，但是想到我们用的类型时 bigint，不太可能会超出范围，</p>
<span id="more"></span>

<p>而且查到<strong>自增 id 达到范围上限后，会出现插入报错，并不会出现负数</strong>，所以排除这种可能性。</p>
<p>之后便是去确认这个值是 MySQL 返回的还是我们用到的 lua-resty-mysql 库基于自己的规则生成的</p>
<ol>
<li>如果是 MySQL 返回，必然是哪里存在 bug，不是 MySQL 的 bug 导致某些行为返回的这个值是负数，就是 lua-resty-mysql 库解析 MySQL 返回值时出现问题。</li>
<li>如果是用到的 lua-resty-mysql 库基于自己的规则生成的，那就是我们使用的方式不对，毕竟 lua-resty-mysql 库的官方说明并没有提供这样的用法</li>
</ol>
<h1 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h1><p>随后开始查看 lua-resty-mysql 库的源码，看到了 res.insert_id 来源这里</p>
<center class="half">
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/resty-mysql-insert_id-来源.png" height="300"/></div>
</center>

<p>因为之前对这份源码不太熟悉，所以第一反应是这个值是 lua-resty-mysql 基于自己的规则生成的（也就是上面的猜测 2），我们不能这样使用。</p>
<p>通过网上搜索我们这种业务场景，也发现别人都是建议使用 MySQL 自带的函数 LAST_INSERT_ID() 来获取这个值（<strong>这种方式和 MySQL 交互两次</strong>），<br>所以我想当然的以为是我们的使用方法错了（后来发现这种想法是错误的，并且网上很少有人提到 MySQL 在 insert 之后已经返回插入的自增 id 值了）。</p>
<p>后来仔细想想，如果是 lua-resty-mysql 基于自己的规则生成的这个值，那么为什么之前这个值都是正确的呢，lua-resty-mysql 又是怎么实现的呢？</p>
<p>基于这个想法，我又打开了源码，发现一开始的理解错了，这个值是基于 MySQL 的响应值解析而来的，上图中 _from_length_coded_bin(packet, pos) 这个函数的作用其实就是解析 MySQL 的二进制响应。</p>
<p>确定了这个问题之后，可以排除上面的猜测 2。<br>回到了猜测 1，但是这里面还漏掉一个原因。</p>
<p>MySQL 返回 insert_id 的这个值是不是代表我们需要的值？<br>或者说，如果 MySQL 官方没有明确说明这个值的含义，只是一个代表其他含义的值，那也不能说是哪里存在 bug，还是我们的使用方法错误，之前的正确只是巧合。</p>
<p>于是开始查阅 <a href="https://dev.mysql.com/doc/internals/en/packet-OK_Packet.html"> MySQL 关于插入后网络响应的官方说明 </a>，很快就找到了这个值。</p>
<center class="half">
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/MySQL-OK-包.png" height="300"/></div>
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/MySQL-int-lenenc.png" height="300"/></div>
</center>

<p>图里明确说明 last_insert_id（也就是我们上面提到的 insert_id）是最后的插入 id 值。</p>
<p>到此，基本可以确定猜测 1 是对的，<strong>MySQL 或者 lua-resty-mysql 库一定哪里存在 bug，导致没有按说明正确返回</strong>。</p>
<p>基于对 MySQL 的信任（毕竟用的人这么多，出错的概率很小，就算有错误一定有人提到过），先假设 lua-resty-mysql 存在问题。</p>
<p>于是我便开始查看 MySQL 的网络协议，需要如何正确解析，以及 lua-resty-mysql 库是否解析正确。</p>
<p><strong>注意这里需要一个背景知识，客户端在向 MySQL Server 发送 insert 语句后（相当于发送请求），MySQL Server 会返回 OK 的包（相当于服务器响应），里面会带有上图中的值</strong>。</p>
<p>可以看到 MySQL 的官方文档里面提到返回的 <a href="https://dev.mysql.com/doc/internals/en/integer.html#packet-Protocol::FixedLengthInteger">last_insert_id</a> 是一个 <strong>int<lenenc></strong> 类型。<br><strong>lenenc</strong> 在 MySQL 里代表变长，需要根据不同的情况分别解析。</p>
<p>对照 lua-resty-mysql 库的源码，发现解析的规则并没有错。</p>
<center class="half">
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/resty-mysql-解析二进制源码.png" height="300"/></div>
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/resty-mysql-解析二进制源码-2.png" height="300"/></div>
</center>

<p>排查到这里就陷入困难了，毕竟 lua-resty-mysql 库对网络协议的解析并没有错，难道是 MySQL 出现 bug 了？如果真是这样，排查起来就困难了，毕竟 MySQL 源码要复杂很多。</p>
<p><strong>其实这里可以用 tcpdump 等工具获取 MySQL 的响应值，分析网络协议中的这个值，来确定是到底是不是 MySQL 的问题，但是因为权限等原因太繁琐，所以不到万不得已就没有这样排查</strong>。</p>
<p>只能先去查一下 <a href="https://bugs.mysql.com/">MySQL 官方的 bug 平台</a>，发现并没有这样的 bug。</p>
<p>本着最后一丝希望，我在 <a href="https://github.com/openresty/lua-resty-mysql/issues">lua-resty-mysql 库的 issue 列表</a> 里搜索 insert_id，</p>
<p>终于发现有人遇到了同样的问题 <a href="https://github.com/openresty/lua-resty-mysql/pull/26">https://github.com/openresty/lua-resty-mysql/pull/26</a>（其实这一步应该最先进行，后面反思里会提到）。</p>
<center class="half">
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/resty-mysql-insert_id-issue-old.png" height="300"/></div>
</center>

<p>里面提到因为 <strong>LuaJIT（可以理解为 lua-resty-mysql 库使用的语言） 位操作只支持 32 位有符号整数，所以 MySQL 的包并没有被正确解析</strong>，可以看到在当时还是 Open 的状态。</p>
<p>这也是为什么我查看源码并没有问题，但还是返回了负数的原因，因为我默认位运算没有 32 位整数的限制（毕竟还有这个限制的很少）。</p>
<p>下面章亦春大大（lua-resty-mysql 库，还有 Openresty 作者）回复，会在 5 月中旬假期回来查看，但那已经是 2015 了，到现在 2021 年 2 月末，过了将近 6 年，还是没有处理~~~</p>
<p>为了查看是否是这个原因，我也去查阅了 <a href="http://bitop.luajit.org/semantics.html">luajit 关于位运算的相关文档</a></p>
<center class="half">
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/luajit-32-位整数.png" height="300"/></div>
</center>

<p>果然文档上写明 <strong>luajit 位运算会返回 32 位有符号整数范围的数字，OpenResty 使用的 luajit 虽然是自己的维护 luajit 分支，但是大部分都和原作者的相同，在这一点上也没有改动</strong>。</p>
<p>后来我自己手动模拟了一遍，发现确实当 Mysql 中自增 id 的值超过 32 位有符号整数上限的时候，这个问题是稳定复现的。</p>
<h1 id="最终结果"><a href="#最终结果" class="headerlink" title="最终结果"></a>最终结果</h1><p>因为之前有一次线上分享加到了章亦春大大的微信，所以干脆直接在微信上联系了章亦春大大。</p>
<p>说明了我的问题和排查到的结果之后，很快得到了回复，并且很快这个 issue 就得到了处理，不得不说，处理的速度还是很快的~</p>
<center class="half">
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/resty-mysql-insert_id-issue.png" height="300"/></div>
</center>

<p>至此，这个 bug 完美排查到并且解决了！</p>
<h1 id="事后反思"><a href="#事后反思" class="headerlink" title="事后反思"></a>事后反思</h1><p>虽然最后这个事情最终结束了，但是还是有一些值得思考的地方。</p>
<ol>
<li>首先，得到的最大的感触是不要重复造轮子，在遇到问题之后，最先确定是否是自己的原因（在这个例子中就是首先确定是否是使用方法错误），<br>下一步骤应该就是查找涉及的 issue 列表，而不是自己再从头排查，我在这个过程也花费了很多时间<br>（当然在这个例子里如果不知道背景知识，比如 MySQL 的 OK 响应包，直接查看 issue 列表也很难发现）；</li>
<li>当然排查的过程中收获也很多，比如对 lua-resty-mysql 库的源码掌握更清晰，对 client 和 MySQL server 之间的网络协议更加了解等等；</li>
<li>最后，对问题应该有刨根问底的精神，而不是网上简单的查不到就跳过，这种做事的方法也是很大的收获。</li>
</ol>
]]></content>
      <categories>
        <category>OpenResty</category>
      </categories>
      <tags>
        <tag>OpenResty</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
</search>
